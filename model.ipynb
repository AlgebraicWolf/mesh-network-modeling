{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "conservative-belize",
   "metadata": {},
   "source": [
    "# Ad-hoc network model \n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hydraulic-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import ipywidgets as widgets\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures as futures\n",
    "from tqdm.notebook import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-raising",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pressed-damage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ebf845e4d74d10a0d123051cc81dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BoundedIntText(value=1, description='Number of datasets:', max=16, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "number_of_datasets = widgets.BoundedIntText(\n",
    "    text = 1,\n",
    "    min = 1,\n",
    "    max = 16,\n",
    "    step = 1,\n",
    "    description = \"Number of datasets:\")\n",
    "\n",
    "display(number_of_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "headed-cigarette",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262b952e51614d1d951b963f11f16486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Path to .csv file')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190085f6f6e94e92a18356e03619fd74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Path to .csv file')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0f31eb35df4882a4e273764de471e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Path to .csv file')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21fa52c6661e43ed9c95bc1e3c8866c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Path to .csv file')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_paths = list()\n",
    "for i in range(number_of_datasets.value):\n",
    "    csv_paths.append(widgets.Text(placeholder=\"Path to .csv file\"))\n",
    "    display(csv_paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sized-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list()\n",
    "\n",
    "for csv_path in csv_paths:\n",
    "    data.append(pd.read_csv(csv_path.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-preservation",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "The goal here is to filter redundant objects (for example, objects that are currently chilling in the object pool) and split data into small pieces by the timeframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "particular-princess",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = list(map(lambda data: data[data.z != -100.0], data)) # Preserve only the objects that are currently somewhere on the map\n",
    "\n",
    "# frames = list(map(lambda data: data.groupby('timestamp'), filtered_data)) # Group data into dataframes with equal timestamp, now each group is a snapshot of a moment in time during recording\n",
    "# group_keys = list(map(lambda frames: frames.groups.keys(), frames)) # Now we can iterate over groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-catch",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "noble-definition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b813db8a5294b629c08025e23ba2939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BoundedFloatText(value=0.0, description='Distance:', max=1000.0, step=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO widget for parameter initialization\n",
    "# Proposed parameters are: Connectivity distance, something about message generation frequency, ???\n",
    "connectivity_dist = widgets.BoundedFloatText(\n",
    "    text = 0.0,\n",
    "    min = 0.0,\n",
    "    max = 1000.0,\n",
    "    step = 1,\n",
    "    description = \"Distance:\",\n",
    "    disabled = False)\n",
    "\n",
    "display(connectivity_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-defensive",
   "metadata": {},
   "source": [
    "## Your actor implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "subject-beginning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Come up with actor interface \n",
    "# TODO implement actor. It should be capable of handling high-level shit like sending message to other use and low-level shit like routing messages inside the network\n",
    "# Are there obvious and correct implementation of the high-level functions that is irrelevant to the protocol of choice? If there is, we should implement them independently of the algo impl (via inheritance)\n",
    "class Actor:\n",
    "    def __init__():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-vinyl",
   "metadata": {},
   "source": [
    "## Model running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hidden-isolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO run model, accumulate some statistics\n",
    "# Proposed stats are: \n",
    "# 1. Connection stability (stability metric could be connection lifetime divided over the simulation length) equipped with standard stat tools (mean, stdev, median, possibly distribution, smth else)\n",
    "# 2. Stats on message delivery efficiency (percentage of successful deliveries, for instance)\n",
    "\n",
    "# TODO wrap everything up in a function, possibly use something like futures in order to parallelize computations for different datasets, in order to allow for parallel processing of many datasets in order to speed up the whole thing\n",
    "\n",
    "# Calculate distance between two people\n",
    "def distance(p1, p2):\n",
    "    return ((p1.x - p2.x) * (p1.x - p2.x) + (p1.y - p2.y) * (p1.y - p2.y) + (p1.z - p2.z) * (p1.z - p2.z)) ** (1/2)\n",
    "\n",
    "# Initialize structures for collecting adjacency data\n",
    "def process_data(filtered_data):\n",
    "    print(' ', end='', flush=True) # Hack to allow for multiple progress bars\n",
    "    \n",
    "    frames = filtered_data.groupby('timestamp')\n",
    "    group_keys = frames.groups.keys()\n",
    "    \n",
    "    ids = filtered_data['id'].unique() # IDs of users\n",
    "\n",
    "    def first(i, j):\n",
    "        return min(ids[i], ids[j])\n",
    "\n",
    "    def second(i, j):\n",
    "        return max(ids[i], ids[j])\n",
    "\n",
    "    # Structure that contains info regarding whether two people were previously connected with one another (Timeframe of connection launch, None otherwise)\n",
    "    connected = dict()\n",
    "\n",
    "    for cur_id in ids:\n",
    "        connected[cur_id] = dict()\n",
    "\n",
    "    for i in range(len(ids)):\n",
    "        for j in range(i + 1, len(ids)): # Iterate over the distinct pairs of people\n",
    "            connected[first(i, j)][second(i, j)] = None # Initialize all pairs as not connected\n",
    "\n",
    "    # Structure that contains info about each connection (two connections between the same two people are distinct iff there exists a snapshot where they aren't connected)\n",
    "    # The sequence A <-> B, A <-> B, A <-/-> B, A <-> B contains two connections between A and B\n",
    "    connections = list() \n",
    "    prev_timestamp = 0\n",
    "\n",
    "    # Nested loops go brrrr (Can we parallelize this piece of shit? Even a little bit?)\n",
    "    for timestamp in tqdm(group_keys): # Iterating over timestamp\n",
    "        # TODO calculate connections between different people in the current timeframe\n",
    "        snapshot = frames.get_group(timestamp) # Get a snapshot of a timestamp\n",
    "\n",
    "        current_connectivity = dict()\n",
    "        for cur_id in ids:\n",
    "            current_connectivity[cur_id] = dict()\n",
    "\n",
    "        for i in range(len(ids)):\n",
    "            for j in range(i + 1, len(ids)):\n",
    "                current_connectivity[first(i, j)][second(i, j)] = False\n",
    "\n",
    "\n",
    "        for i in range(snapshot.shape[0]):\n",
    "            for j in range(i + 1, snapshot.shape[0]): # Iterate over distinct ordered pairs of people \n",
    "                p1 = snapshot.iloc[i]\n",
    "                p2 = snapshot.iloc[j]\n",
    "                dist = distance(p1, p2)\n",
    "                if dist < connectivity_dist.value: # If there is connection present\n",
    "                    current_connectivity[min(p1.id, p2.id)][max(p1.id, p2.id)] = True # Mark it is connected\n",
    "\n",
    "        for i in range(len(ids)):\n",
    "            for j in range(i + 1, len(ids)):\n",
    "                a = first(i, j)\n",
    "                b = second(i, j)\n",
    "\n",
    "                if current_connectivity[a][b]: # If a connection is present \n",
    "                    if connected[a][b] is None: # And it is a new one\n",
    "                        connected[a][b] = timestamp # Add it\n",
    "                elif connected[a][b] is not None: # Otherwise, if the conneciton had just died \n",
    "                    connections.append({'p1': a, 'p2': b, 'timestamp': connected[a][b], 'lifespan': prev_timestamp - connected[a][b]}) # Record connection stats\n",
    "                    current_connectivity[a][b] = None # Delete connection\n",
    "        # Now iterate over all the ids in order to figure out the connections that were dropped out \n",
    "\n",
    "        # TODO check for new/removed connections and update lifetime accordingly\n",
    "        # TODO run shit like message requests etc and call according functions of the actors\n",
    "        # Possibly (somehow?) add message throughput limit so that the graph updates would actually influence message routing procedure. Should prolly discuss the best implementation with other project participants.\n",
    "        prev_timestamp = timestamp\n",
    "        pass\n",
    "\n",
    "    # Close all the connections that are still present\n",
    "    for i in range(len(ids)):\n",
    "        for j in range(i + 1, len(ids)):\n",
    "            a = first(i, j)\n",
    "            b = second(i, j)\n",
    "\n",
    "            if connected[a][b] is not None:\n",
    "                connections.append({'p1': a, 'p2': b, 'timestamp': connected[a][b], 'lifespan': prev_timestamp - connected[a][b]}) # Record connection stats\n",
    "    #             print(\"Added connection info\")\n",
    "                connected[a][b] = None\n",
    "        \n",
    "    return pd.DataFrame(connections)\n",
    "\n",
    "conn_datas = list()\n",
    "# for i in range(number_of_datasets.value):\n",
    "#     conn_datas.append(process_data(filtered_data[i], frames[i], group_keys[i]))\n",
    "\n",
    "conn_datas_promise = list()\n",
    "\n",
    "# with futures.ThreadPoolExecutor(max_workers=4) as e:\n",
    "#     for i in range(number_of_datasets.value):\n",
    "#         conn_datas_promise.append(e.submit(process_data, filtered_data[i], frames[i], group_keys[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "strange-establishment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d332e7edcb0e4bf6b9157099519abddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25afa2e57e0490faa9a5b81bedede6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ffb5be88814910bafb217491c7bbec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c5ccdba5e7472abaaee7fc3962a539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/643 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pool = Pool(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "conditional-secretary",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pool.map(process_data, filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "disabled-loading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>517122</td>\n",
       "      <td>0</td>\n",
       "      <td>39.134022</td>\n",
       "      <td>-1488.308350</td>\n",
       "      <td>28.503515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2818</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.323400</td>\n",
       "      <td>-1440.091431</td>\n",
       "      <td>31.578899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>296962</td>\n",
       "      <td>0</td>\n",
       "      <td>-194.265503</td>\n",
       "      <td>-1672.670654</td>\n",
       "      <td>33.570766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>544002</td>\n",
       "      <td>0</td>\n",
       "      <td>256.717255</td>\n",
       "      <td>-1659.347656</td>\n",
       "      <td>29.133345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17154</td>\n",
       "      <td>0</td>\n",
       "      <td>88.632881</td>\n",
       "      <td>-1409.198120</td>\n",
       "      <td>29.421741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39388</th>\n",
       "      <td>167426</td>\n",
       "      <td>314800</td>\n",
       "      <td>-86.229317</td>\n",
       "      <td>-1581.488037</td>\n",
       "      <td>31.097357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39389</th>\n",
       "      <td>773122</td>\n",
       "      <td>314800</td>\n",
       "      <td>71.822792</td>\n",
       "      <td>-1491.068115</td>\n",
       "      <td>28.858469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39390</th>\n",
       "      <td>156930</td>\n",
       "      <td>314800</td>\n",
       "      <td>-129.334396</td>\n",
       "      <td>-1522.154297</td>\n",
       "      <td>34.132236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39391</th>\n",
       "      <td>546050</td>\n",
       "      <td>314800</td>\n",
       "      <td>299.568298</td>\n",
       "      <td>-1450.562378</td>\n",
       "      <td>29.928701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39392</th>\n",
       "      <td>288258</td>\n",
       "      <td>314800</td>\n",
       "      <td>303.415070</td>\n",
       "      <td>-1591.169800</td>\n",
       "      <td>30.532854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34765 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  timestamp           x            y          z\n",
       "2      517122          0   39.134022 -1488.308350  28.503515\n",
       "3        2818          0  -11.323400 -1440.091431  31.578899\n",
       "4      296962          0 -194.265503 -1672.670654  33.570766\n",
       "6      544002          0  256.717255 -1659.347656  29.133345\n",
       "8       17154          0   88.632881 -1409.198120  29.421741\n",
       "...       ...        ...         ...          ...        ...\n",
       "39388  167426     314800  -86.229317 -1581.488037  31.097357\n",
       "39389  773122     314800   71.822792 -1491.068115  28.858469\n",
       "39390  156930     314800 -129.334396 -1522.154297  34.132236\n",
       "39391  546050     314800  299.568298 -1450.562378  29.928701\n",
       "39392  288258     314800  303.415070 -1591.169800  30.532854\n",
       "\n",
       "[34765 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-integrity",
   "metadata": {},
   "source": [
    "#### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Show collected stats \n",
    "conn_data = conn_datas[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8), facecolor=None)\n",
    "plt.style.use(\"dark_background\")\n",
    "sns.histplot(conn_data, x=\"lifespan\")\n",
    "\n",
    "mean_lifespan = conn_data['lifespan'].mean()\n",
    "median_lifespan = conn_data['lifespan'].median()\n",
    "stdev_lifespan = conn_data['lifespan'].std()\n",
    "\n",
    "plt.axvline(mean_lifespan, color=\"r\", label=\"Mean\")\n",
    "plt.axvline(median_lifespan, color=\"lime\", label=\"Median\")\n",
    "plt.legend()\n",
    "\n",
    "print(\"Mean lifespan:\", mean_lifespan)\n",
    "print(\"lifespan stdev:\", stdev_lifespan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_data.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_data[conn_data.lifespan == 50000].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "101012/314800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list()\n",
    "a.append(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-porcelain",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
